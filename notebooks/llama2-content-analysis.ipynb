{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7357721,"sourceType":"datasetVersion","datasetId":3467388}],"dockerImageVersionId":30636,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Brief\n\nThe model \"meta-llama/Llama-2-7b-chat-hf\" represents a type of Large Language Model (LLM), specifically tailored towards tasks related to text generation and conversation, as hinted by the \"chat-hf\" suffix in its name. Although it's not specifically designed for sentiment analysis, advanced language models like this can be adapted for a variety of Natural Language Processing (NLP) tasks, including sentiment analysis.\n\nModels like \"meta-llama/Llama-2-7b\" are trained on vast amounts of text, enabling them to have a sophisticated understanding of context. They can grasp nuances, ambiguities, and different language styles, which is crucial for sentiment analysis.\n\nIn this notebook, the task is to verify the presence of attributes/characteristics of audit reports (context) based on certain elements of analysis (prompt). This type of sentiment analysis is aimed at verifying the presence or non-presence of these characteristics and therefore mixes sentiment analysis with context analysis.","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\nrtrs_df = pd.read_csv('/kaggle/input/rtrs-brazil-public-audit-reports-2023/brazil_rtrs.csv', encoding = 'iso-8859-14')\nprompt_df = pd.read_csv('/kaggle/input/rtrs-brazil-public-audit-reports-2023/prompt_eng_rtrs.csv')","metadata":{"execution":{"iopub.status.busy":"2024-01-23T13:05:39.719053Z","iopub.execute_input":"2024-01-23T13:05:39.719420Z","iopub.status.idle":"2024-01-23T13:05:39.780088Z","shell.execute_reply.started":"2024-01-23T13:05:39.719389Z","shell.execute_reply":"2024-01-23T13:05:39.778969Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"# Install necessary repositories (transformers, langchain, ...) and login in huggingface","metadata":{}},{"cell_type":"code","source":"!pip install -q transformers einops accelerate langchain bitsandbytes\n","metadata":{"execution":{"iopub.status.busy":"2024-01-23T03:56:49.010104Z","iopub.execute_input":"2024-01-23T03:56:49.010684Z","iopub.status.idle":"2024-01-23T03:57:17.678219Z","shell.execute_reply.started":"2024-01-23T03:56:49.010649Z","shell.execute_reply":"2024-01-23T03:57:17.677229Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ncuml 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ndask-cudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ncudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.0.3 which is incompatible.\ncudf 23.8.0 requires protobuf<5,>=4.21, but you have protobuf 3.20.3 which is incompatible.\ncuml 23.8.0 requires dask==2023.7.1, but you have dask 2023.12.1 which is incompatible.\ncuml 23.8.0 requires distributed==2023.7.1, but you have distributed 2023.12.1 which is incompatible.\ndask-cuda 23.8.0 requires dask==2023.7.1, but you have dask 2023.12.1 which is incompatible.\ndask-cuda 23.8.0 requires distributed==2023.7.1, but you have distributed 2023.12.1 which is incompatible.\ndask-cuda 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.0.3 which is incompatible.\ndask-cudf 23.8.0 requires dask==2023.7.1, but you have dask 2023.12.1 which is incompatible.\ndask-cudf 23.8.0 requires distributed==2023.7.1, but you have distributed 2023.12.1 which is incompatible.\ndask-cudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.0.3 which is incompatible.\ngoogle-cloud-bigquery 2.34.4 requires packaging<22.0dev,>=14.3, but you have packaging 23.2 which is incompatible.\njupyterlab 4.0.10 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\njupyterlab-lsp 5.0.1 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\nlibpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\nmomepy 0.7.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\npymc3 3.11.5 requires numpy<1.22.2,>=1.15.0, but you have numpy 1.24.3 which is incompatible.\npymc3 3.11.5 requires scipy<1.8.0,>=1.7.3, but you have scipy 1.11.4 which is incompatible.\nraft-dask 23.8.0 requires dask==2023.7.1, but you have dask 2023.12.1 which is incompatible.\nraft-dask 23.8.0 requires distributed==2023.7.1, but you have distributed 2023.12.1 which is incompatible.\nspopt 0.6.0 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\nydata-profiling 4.5.1 requires numpy<1.24,>=1.16.0, but you have numpy 1.24.3 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"markdown","source":" # Login Hugginface","metadata":{}},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nsecret_hf = user_secrets.get_secret(\"cli-hf\")\nsecret_wb = user_secrets.get_secret(\"wandb\")","metadata":{"execution":{"iopub.status.busy":"2024-01-23T03:57:17.679705Z","iopub.execute_input":"2024-01-23T03:57:17.680047Z","iopub.status.idle":"2024-01-23T03:57:18.119730Z","shell.execute_reply.started":"2024-01-23T03:57:17.679992Z","shell.execute_reply":"2024-01-23T03:57:18.118934Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"import wandb\n\nwandb.login(key=secret_wb)","metadata":{"execution":{"iopub.status.busy":"2024-01-23T03:57:18.121669Z","iopub.execute_input":"2024-01-23T03:57:18.121946Z","iopub.status.idle":"2024-01-23T03:57:21.491609Z","shell.execute_reply.started":"2024-01-23T03:57:18.121922Z","shell.execute_reply":"2024-01-23T03:57:21.490664Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"wandb.init(project='rtrs-brasil', entity='cleytonacandeira')","metadata":{"execution":{"iopub.status.busy":"2024-01-23T03:57:21.492696Z","iopub.execute_input":"2024-01-23T03:57:21.493166Z","iopub.status.idle":"2024-01-23T03:57:52.485285Z","shell.execute_reply.started":"2024-01-23T03:57:21.493139Z","shell.execute_reply":"2024-01-23T03:57:52.483867Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcleytonacandeira\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.2"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240123_035721-pg9g1mgr</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/cleytonacandeira/rtrs-brasil/runs/pg9g1mgr' target=\"_blank\">splendid-totem-13</a></strong> to <a href='https://wandb.ai/cleytonacandeira/rtrs-brasil' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/cleytonacandeira/rtrs-brasil' target=\"_blank\">https://wandb.ai/cleytonacandeira/rtrs-brasil</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/cleytonacandeira/rtrs-brasil/runs/pg9g1mgr' target=\"_blank\">https://wandb.ai/cleytonacandeira/rtrs-brasil/runs/pg9g1mgr</a>"},"metadata":{}},{"execution_count":5,"output_type":"execute_result","data":{"text/html":"<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/cleytonacandeira/rtrs-brasil/runs/pg9g1mgr?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>","text/plain":"<wandb.sdk.wandb_run.Run at 0x7acb6c634cd0>"},"metadata":{}}]},{"cell_type":"code","source":"from huggingface_hub import HfApi, HfFolder\n\nif secret_hf:\n    HfFolder.save_token(secret_hf)\n    api = HfApi()\n    user = api.whoami(token=secret_hf)\n    print(f\"Logged in as: {user['name']}\")\nelse:\n    print(\"Token not found. Make sure it is set as an secret in add-ons.\")","metadata":{"execution":{"iopub.status.busy":"2024-01-23T03:57:52.486476Z","iopub.execute_input":"2024-01-23T03:57:52.487217Z","iopub.status.idle":"2024-01-23T03:57:52.962058Z","shell.execute_reply.started":"2024-01-23T03:57:52.487189Z","shell.execute_reply":"2024-01-23T03:57:52.960965Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Logged in as: cleytoncandeira\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Pipeline","metadata":{}},{"cell_type":"code","source":"from langchain import HuggingFacePipeline\nfrom transformers import AutoTokenizer\nimport transformers\nimport torch\n\nmodel = \"meta-llama/Llama-2-7b-chat-hf\"\n\ntokenizer = AutoTokenizer.from_pretrained(model)\n\npipeline = transformers.pipeline(\n    \"text-generation\", #task\n    model=model,\n    tokenizer=tokenizer,\n    torch_dtype=torch.bfloat16,\n    trust_remote_code=True,\n    device_map=\"auto\",\n    max_length=1000,\n    do_sample=True,\n    top_k=10,\n\n    num_return_sequences=1,\n    eos_token_id=tokenizer.eos_token_id\n)","metadata":{"execution":{"iopub.status.busy":"2024-01-23T03:57:52.963507Z","iopub.execute_input":"2024-01-23T03:57:52.963847Z","iopub.status.idle":"2024-01-23T03:59:16.626471Z","shell.execute_reply.started":"2024-01-23T03:57:52.963816Z","shell.execute_reply":"2024-01-23T03:59:16.625167Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/1.62k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"54372776bc2d41769b57e2ae17a723ce"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4bfc8930acb843e984e1543b8292d105"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"684b81ad522f42a7a9b51f363fc7aa9e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fb951e1b5e554877ab644f3140943c7a"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/614 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0321502c4c1a4b0c90ba914f5c5c4473"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/26.8k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5dda92ddffe846b98c8662f29776f775"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ac1dd7dc779f4ef4ae54861930046b61"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00002.safetensors:   0%|          | 0.00/9.98G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4f1c94065c4842cc9c95475e5988d18a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00002.safetensors:   0%|          | 0.00/3.50G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"96092bcf1afd4f53a891077514420538"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bf73a3196305457eb1686e719fbfe5f8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/188 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e240960d46e147769231db6a538bb043"}},"metadata":{}}]},{"cell_type":"code","source":"llm = HuggingFacePipeline(pipeline = pipeline, model_kwargs = {'temperature':0})","metadata":{"execution":{"iopub.status.busy":"2024-01-23T03:59:16.628139Z","iopub.execute_input":"2024-01-23T03:59:16.628987Z","iopub.status.idle":"2024-01-23T03:59:16.636686Z","shell.execute_reply.started":"2024-01-23T03:59:16.628946Z","shell.execute_reply":"2024-01-23T03:59:16.635735Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"from langchain import PromptTemplate,  LLMChain\n\ntemplate = \"\"\"\n            Given the environmental audit criteria and observations, identify key features and concepts.\n            Also, evaluate if these features are present in the provided audit evaluation text.\n            Use the format ['feature', 'yes/no'] for the response, where 'yes' indicates presence and 'no' indicates absence.\n            Criteria and Observations: ```{criteria_observations}```\n            Audit Evaluation Text: ```{audit_text}```\n           \"\"\"\n\nprompt = PromptTemplate(template=template, input_variables=[\"criteria_observations\", \"audit_text\"])\n\nllm_chain_example = LLMChain(prompt=prompt, llm=llm)\n","metadata":{"execution":{"iopub.status.busy":"2024-01-23T03:59:16.637860Z","iopub.execute_input":"2024-01-23T03:59:16.638230Z","iopub.status.idle":"2024-01-23T03:59:26.031158Z","shell.execute_reply.started":"2024-01-23T03:59:16.638204Z","shell.execute_reply":"2024-01-23T03:59:26.030198Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"# Example","metadata":{}},{"cell_type":"code","source":"criteria_observations = \"\"\"1.1.1 There is demonstrable knowledge of responsibilities under applicable laws;\n                        1.1.2 Applicable laws are being complied with;\n                        1.1.3 Producers must not engage in any act of corruption, extortion or embezzlement,\n                        or in any form of bribery - including (but not limited to) promising, offering, giving or accepting any undue inducement, whether monetary or otherwise.\"\"\"\n\naudit_text = \"\"\"Evidenced through documentary evaluation and interviews with managers, that the farm has a control system based on a table which contains the\n                    \\x93applicable legislation and applicable laws Santa Cruz Farm\\x94, containing Norms, Decrees , Laws and other legislation pertinent to the operation\n                  of the farm and maintains a service provision contract with third-party companies, responsible for maintaining licenses and other mandatory regulatory\n                  documents in accordance with applicable legislation.\n              The farm has implemented an anti-corruption policy and it is disseminated among all employees in key sectors.\"\"\"\n\noutput = llm_chain_example.invoke({\"criteria_observations\": criteria_observations, \"audit_text\": audit_text})","metadata":{"execution":{"iopub.status.busy":"2024-01-23T13:07:33.236557Z","iopub.execute_input":"2024-01-23T13:07:33.236921Z","iopub.status.idle":"2024-01-23T13:07:47.816150Z","shell.execute_reply.started":"2024-01-23T13:07:33.236890Z","shell.execute_reply":"2024-01-23T13:07:47.815068Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"print(output)","metadata":{"execution":{"iopub.status.busy":"2024-01-23T13:07:47.818057Z","iopub.execute_input":"2024-01-23T13:07:47.819206Z","iopub.status.idle":"2024-01-23T13:07:47.826406Z","shell.execute_reply.started":"2024-01-23T13:07:47.819167Z","shell.execute_reply":"2024-01-23T13:07:47.825485Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"{'criteria_observations': '1.1.1 There is demonstrable knowledge of responsibilities under applicable laws;\\n                        1.1.2 Applicable laws are being complied with;\\n                        1.1.3 Producers must not engage in any act of corruption, extortion or embezzlement,\\n                        or in any form of bribery - including (but not limited to) promising, offering, giving or accepting any undue inducement, whether monetary or otherwise.', 'audit_text': 'Evidenced through documentary evaluation and interviews with managers, that the farm has a control system based on a table which contains the\\n                    \\x93applicable legislation and applicable laws Santa Cruz Farm\\x94, containing Norms, Decrees , Laws and other legislation pertinent to the operation\\n                  of the farm and maintains a service provision contract with third-party companies, responsible for maintaining licenses and other mandatory regulatory\\n                  documents in accordance with applicable legislation.\\n              The farm has implemented an anti-corruption policy and it is disseminated among all employees in key sectors.', 'text': \" Response:\\n            ['1.1.1', 'yes']\\n            ['1.1.2', 'yes']\\n            ['1.1.3', 'yes']\\n            ['1.1.4', 'no'] (as the text does not mention anything about a control system based on a table)\\n        Explanation:\\n            Based on the provided audit evaluation text, the following key features and concepts are identified:\\n                * Knowledge of responsibilities under applicable laws: Yes, the text mentions that the farm has a control system based on a table which contains applicable legislation and norms.\\n                * Compliance with applicable laws: Yes, the text states that the farm maintains a service provision contract with third-party companies responsible for maintaining licenses and other mandatory regulatory documents in accordance with applicable legislation.\\n                * Anti-corruption policy: Yes, the text mentions that the farm has implemented an anti-corruption policy and it is disseminated among all employees in key sectors.\\n                * Control system based on a table: No, the text does not mention anything about a control system based on a table.\\n\\nNote: The response is based on the information provided in the audit evaluation text and the criteria and observations provided in the question.\"}\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Analysis RTRS Dataset","metadata":{}},{"cell_type":"code","source":"batch_size = 32","metadata":{"execution":{"iopub.status.busy":"2024-01-23T03:59:26.033765Z","iopub.execute_input":"2024-01-23T03:59:26.034391Z","iopub.status.idle":"2024-01-23T03:59:26.043490Z","shell.execute_reply.started":"2024-01-23T03:59:26.034364Z","shell.execute_reply":"2024-01-23T03:59:26.042278Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"def process_batch(batch, llm_chain, prompt):\n    batch_outputs = []\n    for obs in batch:\n        output = llm_chain.invoke({\"criteria_observations\": prompt, \"audit_text\": obs})\n        batch_outputs.append(output)\n    return batch_outputs","metadata":{"execution":{"iopub.status.busy":"2024-01-23T03:59:26.044785Z","iopub.execute_input":"2024-01-23T03:59:26.045460Z","iopub.status.idle":"2024-01-23T03:59:26.054440Z","shell.execute_reply.started":"2024-01-23T03:59:26.045423Z","shell.execute_reply":"2024-01-23T03:59:26.053337Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm\n\nresult_llama2_df = pd.DataFrame(columns=rtrs_df.iloc[64:, 12:].columns)\n\nfor idx, col in tqdm(enumerate(rtrs_df.iloc[:, 12:].columns), total=len(rtrs_df.iloc[:, 12:].columns)):\n    prompt_text = prompt_df.iloc[idx]['Describe']\n    \n    observations = rtrs_df[col][:64]\n\n    current_batch = []\n    column_results = []\n\n    for obs in observations:\n        formatted_input = {\n            \"criteria_observations\": prompt_text,\n            \"audit_text\": obs\n        }\n        current_batch.append(template.format(**formatted_input))\n\n        if len(current_batch) == batch_size:\n            batch_outputs = pipeline(current_batch)\n            column_results.extend([output[0]['generated_text'] for output in batch_outputs])\n            current_batch = []\n\n    if current_batch:\n        batch_outputs = pipeline(current_batch)\n        column_results.extend([output[0]['generated_text'] for output in batch_outputs])\n\n    result_llama2_df[col] = column_results\n    wandb.log({f'{col}_processed': len(column_results)})\n","metadata":{"execution":{"iopub.status.busy":"2024-01-23T03:59:26.055800Z","iopub.execute_input":"2024-01-23T03:59:26.056314Z","iopub.status.idle":"2024-01-23T12:27:25.381098Z","shell.execute_reply.started":"2024-01-23T03:59:26.056280Z","shell.execute_reply":"2024-01-23T12:27:25.380049Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stderr","text":" 18%|█▊        | 5/28 [1:28:43<7:07:13, 1114.50s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\n 25%|██▌       | 7/28 [2:07:53<6:41:30, 1147.16s/it]/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 1020, but `max_length` is set to 1000. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 1353, but `max_length` is set to 1000. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 1026, but `max_length` is set to 1000. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 1022, but `max_length` is set to 1000. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n  warnings.warn(\n100%|██████████| 28/28 [8:27:59<00:00, 1088.55s/it]  \n","output_type":"stream"}]},{"cell_type":"code","source":"result_llama2_df.to_csv('result_llama2_df.csv')","metadata":{"execution":{"iopub.status.busy":"2024-01-23T12:27:35.391696Z","iopub.execute_input":"2024-01-23T12:27:35.392080Z","iopub.status.idle":"2024-01-23T12:27:35.613199Z","shell.execute_reply.started":"2024-01-23T12:27:35.392049Z","shell.execute_reply":"2024-01-23T12:27:35.612061Z"},"trusted":true},"execution_count":14,"outputs":[]}]}